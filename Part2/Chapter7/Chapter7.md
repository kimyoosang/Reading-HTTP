# Chapter7. 캐시

- 웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치다. 웹 요청이 캐시에 도착했을 때, 캐시된 로컬 사본이 존재한다면, 그 문서는 원 서버가 아니라 그 캐시로부터 제공된다
- 캐시는 다음과 같은 혜택을 준다
  1. 캐시는 불필요한 데이터 전송을 줄여서, 네트워크 요금으로 인한 비용을 줄여준다
  2. 캐시는 네트워크 병목을 줄여준다. 대역폭을 늘리지 않고도 페이지를 빨리 불러올 수 있게 된다
  3. 캐시는 원 서버에 대한 요청을 줄여준다. 서버는 부하를 줄일 수 있으니 더 빨리 응답할 수 있게 된다
  4. 페이지를 먼 곳에서 불러올수록 시간이 많이 걸리는데, 캐시는 거리로 인한 지연을 줄여준다

## **7.1 불필요한 데이터 전송**

- 복수의 클라이언트가 자주 쓰이는 원 서버 페이지에 접근할 때, 서버는 같은 문서를 클라이언트들에게 각각 한 번씩 전송하게 된다. 똑같은 바이트들이 네트워크를 통해 계속 반복해서 이동한다. 이 불필요한 데이터 전송은 값비싼 네트워크 대역폭을 잡아먹고, 전송을 느리게 만들며, 웹 서버에 부하를 준다
- 캐시를 이용하면, 첫 번째 서버 응답은 캐시에 보관된다. 캐시된 사본이 뒤이은 요청들에 대한 응답으로 사용될 수 있게 때문에, 원 서버가 중복해서 트래픽을 주고받는 낭비가 줄어들게 된다

## **7.2 대역폭 병목**

- 캐시는 또한 네트워크 병목을 줄여준다. 많은 네트워크가 원격 서버보다 로켓 네트워크 클라이언트에 더 넓은 대역폭을 제공한다. 클라이언트들이 서버에 접근할 때의 속도는, 그 경로에 있는 가장 느린 네트워크의 속도와 같다. 만약 클라이언트가 빠른 LAN에 있는 캐시로부터 사본을 가져온다면, 캐싱은 성능을 대폭 개선할 수 있을 것이다
- 대역폭은 큰 묵서에 대해 현저한 지원을 일으키며, 속도는 네트워크 종류의 차이에 따라 극적으로 달라진다. 이더넷 LAN이라면 5M 크기의 파일을 전송하는데 1초도 걸리지 않지만, 56-Kbps 모뎀이라면 749초(12분 이상)이 걸릴 것이다

## **갑작스런 요청 쇄도(Flash Crowds)**

- 캐싱은 갑장스런 요청 쇄도에 대처하기 위해 특히 중요하다. 갑작스런 사건으로 인해 많은 사람이 거의 동시에 웹 문서에 접근할 때 이런 일이 발생한다
- 이 결과로 초래된 불필요한 트래픽의 급증은 네트워크와 웹 서버에 심각한 장애를 야기시킨다

## **7.4 거리로 인한 지연**

- 비록 대역폭이 문제가 되지 않더라도, 거리가 문제가 될 수 있다. 모든 네트워크 라우터는 제각각 인터넷 트래픽을 지연시킨다. 그리고 클라이언트와 서버 사이에 라우터가 그다지 많지 않더라도, 빛의 속도 그 자체가 유의미한 지연을 유발한다

## **7.5 적중과 부적중**

- 캐시가 세상 모든 문서의 사본을 저장하지는 않는다
- 캐시에 요청이 도착했을 때, 만약 그에 대응하는 사본이 있다면 그를 이용해 요청이 처리될 수 있다. 이것을 **캐시 적중**이라고 부른다. 만약 대응하는 사본이 없다면 그냥 원서버로 전달되기만 할 뿐이다. 이것을 **캐시 부적중**이라고 부른다

### **7.5.1 재검사**

- 원 서버 콘텐츠는 변경될 수 있기 때문에, 캐시는 반드시 그들이 갖고 있는 사본이 여전히 최신인지 서버를 통해 때때로 점검해야 한다. 이러낳 '신선도 검사'를 **HTTP 재검사**라고 부른다. 효과적인 재검사를 위해, HTTP는 서버로부터 전체 객체를 가져오지 않고도 콘텐츠가 여전히 신선한지 빠르게 검사할 수 있는 특별한 요청을 정의했다
- 캐시는 스스로 원한다면 언제든지 사본을 재검사할 수 있다. 그러나 캐시가 문서를 수백만 개씩 갖고 있는 경우가 흔한데 비해 네트워크 대역폭은 부족하기 때문에, 대부분의 캐시는 클라이언트가 사본을 요청하였으며 그 사본이 검사를 할 필요가 있을 정도로 충분히 오래된 경우에만 재검사를 한다
- 캐시는 캐시된 사본의 재검사라 필요할 때, 원 서버에 작은 재검사 요청을 보낸다. 콘텐츠가 변경되지 않았다면, 서버는 아주 작은 304 Not Modified 응답을 보낸다. 그 사본이 여전히 유효함을 알게 된 캐시는 즉각 사본이 신선하다고 임시로 다시 표시한 뒤 그 사본을 클라이언트에게 제공한다. 이를 **재검사 적중** 혹은 **느린 적중**이라고 부른다. 이것은 순수 캐시 적중보다 느린데, 원 서버와 검사를 할 필요가 있기 때문이다. 그러나 캐시 부적중 보다는 빠른데, 서버로부터 객체 데이터를 받아올 필요가 없기 때문이다
- HTTP는 캐시된 객체를 재확인 하기 위한 몇 가지 도구를 제공하는데, 그 중에서 가장 많은 쓰이는 것은 If-Modified-Since 헤더다. 서버에게 보내는 GET 요청에 이 헤더를 추가하면 캐시된 시간 이후에 변경된 경우에만 사본을 보내달라는 의미가 있다
- GET If-Modified-Since 요청이 서버에 도착했을 때 일어날 수 있는 세 가지 상황
  1. **재검사 적중**
  - 만약 서버 객체가 변경되지 않았다면, 서버는 클라이언트에게 작은 HTTP 304 Not Midified 응답을 보낸다
  2. **재검사 부적중**
  - 만약 서버 객체가 캐시된 사본과 다르다면, 서버는 콘텐츠 전체와 함께 평범한 HTTP 200 OK 응답을 클라이언트에게 보낸다
  3. **객체 삭제**
  - 만약 서버 객체가 삭제되었ㄷ가면, 서버는 404 Not Found 응답을 돌려보내며, 캐시는 사본을 삭제한다

### **7.5.2 적중률**

- 캐시가 요청을 처리하는 비율을 캐시 적중률, 혹은 문서 적중률 이라고 부르기도 한다. 적중률은 0에서 1까지의 값으로 되어 있지만, 흔히 퍼센트로 표현되기도 한다. 0%는 모든 요청이 캐시 부적중임을, 그리고 100%는 모든 요청이 캐시 적중임을 의미한다
- 캐시 관리자는 캐시 적중률이 100%에 근접하게 되는 것을 좋아할 것이다. 실제 적중률은 캐시가 얼마나 큰지, 캐시 사용자들의 관심사가 얼마나 비슷한지, 캐시된 데이터가 얼마나 자주 변경되거나 개인화되는지, 캐시가 어떻게 설정되어 있는지에 달려있다. 적중률은 예측하기 어려운 것으로 악명이 높지만 오늘날 적중률 40%면 웹 캐시로 괜찮은 편이다
- 보통 크기의 캐시라도 충분한 분량의 자주 쓰이는 문서들을 보관하여 상당히 트래픽을 줄이고 성능을 개선할 수 있다. 캐시는 유용한 콘텐츠가 캐시 안에 멈르도록 보장하기 위해 노력한다

### **7.5.3 바이트 적중률**

- 문서들이 모두 같은 크기인 것은 아니기 때무넹 문서 적중률이 모든 것을 말해주지는 않는다. 몇몇 큰 객체는 덜 접근되지만 그 크기 때무넹 전체 트래픽에는 더 크게 기여한다. 이런 이유로, 어떤 사람들은 바이트 단위 적중률 측정값을 더 선호한다
- 바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현한다. 이 측정값은 트래픽이 절감된 정도를 포착해낸다. 바이트 단위 적중률 100%는 모든 바이트가 캐시에서 왔으며, 어떤 트래픽도 인터넷으로 나가지 않았음을 의미한다
- 문서 적중률과 바이트 단위 적중률은 둘 다 캐시 성능에 대한 유용한 지표다. 문서 적중률은 얼마나 많은 웹 트랜잭션ㅇ을 외부로 내보내지 않았는지 보여준다. 트랙잭셔너은 고정된 소요 시간을 포함하게 되는데, 이것은 종종 길 수도 있기 떄문에 문서 적중률을 개선하면 전체 대기시간이 줄어든다
- 바이트 단위 적중률은 얼마나 많은 바이트가 인터넷으로 나가지 않았는지 보여준다. 바이트 단위 적중률의 개선은 대역폭 절약을 최적화한다

### **7.5.4 적중과 부적중의 구별**

- HTTP는 클라이언트에게 응답이 캐시 적중이었는지 아니면 원 서버 접근인지 말해줄 수 있는 방법을 제공하지 않는다. 두 경우 모두 응답 코드는 응답이 본문을 갖고 있음을 의미하는 200OK가 될 것이다. 어떤 상용 프락시 캐시는 캐시에 무슨 일이 일어났는지 설명하기 위해 Via 헤더에 추가 정보를 붙인다
- 클라이언트가 응답의 Date 헤더 값을 현재 시각과 비교하여, 응답의 생성일이 더 오래되었다면 클라이언트는 응답이 캐시된 것임을 알아낼 수 있다. 클라이언트가 캐시된 응답을 감지하는 또 다른 방법은, 응답이 얼마나 오래되었는지 말해주는 Age 헤더를 이용하는 것이다

## **7.6 캐시 토폴로지**

- 캐시는 한 명의 사용자에게만 할당될 수도 있고 반대로 수천 명의 사용자들 간에 공유될 수도 있다. 한 명에게남 할당된 캐시를 **개인 전용 캐시**라 부른다. 개인 전용 캐시는 개인마을 위한 캐시리므로, 한 명의 사용자가 자주 찾는 페이지를 담는다
- 공유된 캐시는 **공용 캐시**라고 불린다. 공용 캐시는 사용자 집단에게 자주 쓰이는 페이지를 담는다

### **7.6.1 개인 전용 캐시**

- 개인 전용 캐시는 많은 에너지나 저장 공간을 필요로 하지 않으므로, 작고 저렴할 수 있다. 웹 브라우저는 개인 전용 캐시를 내장하고 있다. 대부분의 브라우저는 자주 쓰이는 문서를 개인용 컴퓨터의 디스크와 메모리에 캐시해 놓고, 사용자가 캐시 사이즈와 설정을 수정할 수 있도록 허용한다. 캐시에 어떤 것들이 들어있는지 확인하기 위해 브라우저 안을 들여다보는 것도 가능하다

### **7.6.2 공용 프락시 캐시**

- 공용 캐시는 캐시 프락시 서버 혹은 더 흔히 프락시 캐시라고 불리는 특별한 종류의 공유된 프락시 서버다. 프락시 캐시는 로컬 캐시에서 문서를 제공하거나, 혹은 사용자의 입장에서 서버에 접근한다. 캐시에는 여러 사용자가 접근하기 때문에, 불필요한 트래픽을 줄일 수 있는 더 많은 기회가 있다
- 프락시 캐시는 수동 프락시를 지정하거나 프락시 자동설정 파일을 설정함으로써 브라우저가 프락시 캐시를 사용하도록 설정할 수 있다
- 또한 인터셉트 프락시를 사용함으로써 브라우저의 설정 없이 HTTP 요청이 캐시를 통하도록 강제할 수 있다

### **7.6.3 프락시 캐시 계층들**

- 작은 캐시에서 캐시 부적중이 발생했을 대 더 큰 부모 캐시가 그 '걸러 남겨진' 트래픽을 처리하도록 하는 계층을 만든 방식이 합리적인 경우가 많다
- 두 단계에 캐시 계층
  - 클라이언트 주위에는 작고 저렴한 캐시를 사용하고, 계층 상단에는 많은 사용자들에 의해 공유되는 문서를 유지하기 위해 더 크고 강력한 캐시를 사용한다
  - 1단계 캐시에서 적중을 얻는다면 다행일 것이다. 그러나 그렇지 못했다면 더 큰 부모 캐시가 사용자의 요청을 처리할 수 있을 것이다
  - 캐시 계층이 깊다면 요청은 캐시의 긴 연쇄를 따라가게 될 것이다. 프락시 연쇄가 길어질수록 각 중간 프락시는 현저한 성능 저하가 발생할 것이다

### **7.6.4 캐시망, 콘텐츠 라우팅, 피어링**

- 몇몇 네트워크 아키텍처는 단순한 캐시 계층 대신 복잡한 캐시망을 만든다. 캐시망의 프락시 캐시는 복잡한 방법으로 서로 대화하여, 어떤 부모 캐시와 대화할 것인지, 아니면 요청이 캐시를 완전히 우회해서 원 서버로 바로 가도록 할 것인지에 대한 캐시 머큐니케이션 결정을 동적으로 내린다
- 캐시망 안에서의 콘텐츠 라우팅을 위해 설계된 캐시들은 다음에 나열된 일들을 모두 할 수 있을 것이다
  1. URL에 근거하여, 부모 캐시와 원 서버 중 하나를 동적으로 선택한다
  2. URL에 근거하여 특정 부모 캐시를 동적으로 선택한다
  3. 부모 캐시에게 가기 전에, 캐시된 사본을 로컬에서 찾아본다
  4. 다른 캐시들이 그들의 캐시된 콘텐츠의 부분적으로 접근할 수 있도록 허용하되, 그들의 캐시를 통한 인터넷 트랜짓은 허용하지 않는다
- 이러한 한층 더 복잡한 캐시 사이의 관계는, 서로 다른 조직들이 상호 이득을 위해 그들의 캐시를 연결하여 서로를 찾아볼 수 있도록 해준다. 선택적인 피어링을 지원하는 캐시는 **형제 캐시**라고 부른다
- HTTP는 형제 캐시를 지원하지 않기 때문에, 사람들은 인터넷 캐시 프로토콜(ICP)나 하이퍼텍스트 캐시 프로토콜(HTCP)같은 프로토콜을 이용해 HTTP를 확장했다
